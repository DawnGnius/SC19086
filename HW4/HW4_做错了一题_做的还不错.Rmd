---
title: "Homework 4"
author: "By 19086"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('snowfall')
```

## Question 1 (Exercise 6.7)
Estimate the power of the skewness test of normality against symmetric $Beta(\alpha, \alpha)$ distributions and comment on the results. 
Are the results different for heavy-tailed symmetric alternatives such as $t(ν)$?


## Answer 1

The skewness $\sqrt{b_1}$ of a random variable $X$ is defined by
\begin{equation}
  \sqrt{b_{1}} = 
    \frac{\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{3}}
    {\left(\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\right)^{3 / 2}},
\end{equation}
which is asymptotically normal with mean $0$ and variance $6/n$ under normality assumption of $X$.

The skewness test of normality is done with hypotheses
\begin{equation}
H_0: \sqrt{\beta_1} = 0 \Leftrightarrow  H_1: \sqrt{\beta_1} \neq 0 .
\end{equation}
where the sampling distribution of the skewness statistic is derived under the assumption of normality.

Our goal is to estimate the power of the skewness test of normality against symmetric $Beta(\alpha, \alpha)$ distributions.
We just need to generate data from $Beta(\alpha, \alpha)$ distributions with some different values of $\alpha$ and then put then into the test machine as described above.

Let's focuse on the code
```{r}
set.seed(1111)
n <- 30   # sample size
m <- 2500  # reputation times

# statistics function
skewness <- function(x){
  # input data x
  # return statistics b1
  x_bar <- mean(x)
  numerator <- mean((x-x_bar)^3)
  denominator <- (mean((x-x_bar)^2))^1.5
  return(numerator / denominator)
}

# critical value for the skewness test at level=0.1
cv <- qnorm(1-0.1/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))

# replicate the procedure with different parameter alpha
pwr <- function(a){
  stat <- replicate(m, expr={
                    X <- rbeta(n, a, a)
                    skewness(X) })
  length(which(abs(stat) >= cv)) / m
}

# calculate power
alpha <- seq(0, 40, length.out=81)[-1]
powers <- unlist(base::lapply(X=alpha, FUN=pwr))

# plot power vs alpha
plot(alpha, powers, type = "b", xlab = bquote(alpha), ylab='Power', ylim = c(0,1))

# plot test level line, horizon
abline(h = .1, lty = 3)

# add standard errors
se <- sqrt(powers * (1-powers) / m) 
lines(alpha, powers+se, lty = 3)
lines(alpha, powers-se, lty = 3)
```

The power of the test procedure is really poor. 
It can hardly reject the hypotheses under such a kind of data $Beta(\alpha,\alpha), \alpha=0.5,1,\cdots,40$. 

To explain the result, I suppose when $\alpha$ is large, such as $20$, kurtosis is relatively large, which means the variance is small. At this time, $Beta(\alpha,\alpha)$ is similar with normal distribution.
On the contrary, when $\alpha$ is small, the variance is relatively small, but it's very small actually. So it's impossible for the test machine to reject the null hypothesis.

Now let's check the reusult of some other heavy-tailed symmetric alternatives such as $t(ν)$.

Please see the code for detail.
```{r}
alpha <- seq(1, 40)
# replicate the procedure with different parameter alpha
pwr <- function(a){
  stat <- replicate(m, expr={
                    X <- rt(n, a)
                    skewness(X) })
  length(which(abs(stat) >= cv)) / m
}
powers <- unlist(base::lapply(X=alpha, FUN=pwr))

# plot power vs alpha
plot(alpha, powers, type = "b", xlab = 'Degree of Freedom', ylab='Power', ylim = c(0,1))

# plot test level line, horizon
abline(h = .1, lty = 3)

# add standard errors
se <- sqrt(powers * (1-powers) / m) 
lines(alpha, powers+se, lty = 3)
lines(alpha, powers-se, lty = 3)
```

We can see that the test procedure works well when the parameter of $t$ distribution, $df$, is relatively small. The power is about $0.9$ at the beginning, and it declines rapidly when $df$ becomes bigger. When the power is about $0.2$ and $df$ is about $8$, it slowed down the rate of decline and it slowly reduce to $0.1$, the level we selected, in the following process. 

I suppoese that, it is because $t$ distribution is different from normal distribution when $df$ is small, but when $df$ is larger they are similar. 

## Question 2 (Project 6.A)
Tests for association based on Pearson product moment correlation $\rho$, Spearman’s rank correlation coefficient $\rho_s$, or Kendall’s coefficient $\tau$, are implemented in **cor.test**.
Show (empirically) that the nonparametric tests based on $\rho_s$ or $\tau$ are less powerful than the correlation test when the sampled distribution is bivariate normal. 
Find an example of an alternative (a bivariate distribution $(X, Y)$ such that $X$ and $Y$ are dependent) such that at least one of the nonparametric tests have better empirical power than the correlation test against this alternative.


## Answer 2

```{r}
library(MASS) # Simulate from a Multivariate Normal Distribution
set.seed(1111)
n <- 30
m <- 2500

pwr <- function(meth, rho){
  Sig <- matrix(c(1, rho, rho, 1), 2, 2)
  X <- mvrnorm(n, c(0, 0), Sig)
  x <- X[, 1]; y <- X[, 2]
  if(cor.test(x, y, method=meth)$p.value<0.05){
    return(1)
  } else {
    return(0)
  }
}

# calculate the power with different method
rho <- seq(0,1,length.out=50)
pwr.pearson <- unlist(base::lapply(X=rho, FUN=function(rho){sum(unlist(base::replicate(m, expr={pwr("pearson", rho)}))) / m}))
pwr.kendall <- unlist(base::lapply(X=rho, FUN=function(rho){sum(unlist(base::replicate(m, expr={pwr("kendall", rho)}))) / m}))
pwr.spearman <- unlist(base::lapply(X=rho, FUN=function(rho){sum(unlist(base::replicate(m, expr={pwr("spearman", rho)}))) / m}))

# plot them into one figure
plot(rho, pwr.pearson, type="b", xlab=bquote(rho), ylab='Power', col=1, main='Comparation between nonpara. and para. method')
lines(rho, pwr.kendall, type="b", col=2)
lines(rho, pwr.spearman, type="b", col=3)
legend("topleft", legend=c('pearson', 'kendall', 'spearman'), col=c(1,2,3), lty=1)
```

From the figure above, we can say the nonparametric tests based on $\rho_s$ or $\tau$ are less powerful than the correlation test when the sampled distribution is bivariate normal. But the difference is small, we could still use nonparameter method. 

Now let's check some other distribution like multivariate normal mixture.
```{r}
set.seed(1111)
# Multivariate normal mixture
loc.mix.0 <- function(n, p, mu1, mu2, Sigma) {
  X <- matrix(0, n, 2)
  for (i in 1:n) {
    k <- rbinom(1, size = 1, prob = p)
    if (k){
      X[i,] <- mvrnorm(1, mu = mu1, Sigma)
    } else {
    X[i,] <- mvrnorm(1, mu = mu2, Sigma)
    }
  }
  return(X)
}

pwr <- function(meth, rho){
  Sig <- matrix(c(1, rho, rho, 1), 2, 2)
  X <- loc.mix.0(n, 0.5, c(0, 5), c(5, 0), Sig)
  x <- X[, 1]; y <- X[, 2]
  if(cor.test(x, y, method=meth)$p.value<0.05){
    return(1)
  } else {
    return(0)
  }
}

# calculate the power with different method
sfInit(parallel = TRUE, cpus = 10)
sfLibrary(MASS)
sfExport("n", "m", "rho")
sfExport("loc.mix.0", "pwr")
pwr.pearson <- unlist(sfLapply(X=rho, FUN=function(rho){sum(unlist(base::replicate(m, expr={pwr("pearson", rho)}))) / m}))
pwr.kendall <- unlist(sfLapply(X=rho, FUN=function(rho){sum(unlist(base::replicate(m, expr={pwr("kendall", rho)}))) / m}))
pwr.spearman <- unlist(sfLapply(X=rho, FUN=function(rho){sum(unlist(base::replicate(m, expr={pwr("spearman", rho)}))) / m}))
sfStop()

# plot them into one figure
plot(rho, pwr.pearson, type="b", xlab=bquote(rho), ylab='Power', ylim=c(0,1), col=1, main='Comparation between nonpara. and para. method')
lines(rho, pwr.kendall, type="b", col=2)
lines(rho, pwr.spearman, type="b", col=3)
legend("topleft", legend=c('pearson', 'kendall', 'spearman'), col=c(1,2,3), lty=1)

```

Now, from the figure we can see that nonparameter test works better than correction test. It shous the good compatibility of nonparameter method.

